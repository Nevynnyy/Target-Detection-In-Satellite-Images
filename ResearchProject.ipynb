{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import math\n",
    "import cv2 as cv\n",
    "import random\n",
    "import math\n",
    "import skimage as sk\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "\n",
    "In this stage,we:\n",
    "\n",
    "1.import the images.\n",
    "\n",
    "2.Convert images from the RGB format to grayscale images.\n",
    "\n",
    "3.Resize(Not crop or scale) the converted images to be 32x32 images.\n",
    "\n",
    "4.Divide the 18 images into 8 training images and 10 testing images.\n",
    "\n",
    "5.Flatten those images so that they can become signals and then concatinate signals such that each signal is a row in a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Dataset\n",
    "img1 = io.imread('2S1.JPG')\n",
    "img1 = sk.color.rgb2gray(img1)\n",
    "img1 = resize(img1,(32,32),anti_aliasing=True)\n",
    "\n",
    "img2 = io.imread('BRDM2.JPG')\n",
    "img2 = sk.color.rgb2gray(img2)\n",
    "img2 = resize(img2,(32,32),anti_aliasing=True)\n",
    "\n",
    "img3 = io.imread('BTR60.JPG')\n",
    "img3 = sk.color.rgb2gray(img3)\n",
    "img3 = resize(img3,(32,32),anti_aliasing=True)\n",
    "\n",
    "img4 = io.imread('D7.JPG')\n",
    "img4 = sk.color.rgb2gray(img4)\n",
    "img4 = resize(img4,(32,32),anti_aliasing=True)\n",
    "\n",
    "img5 = io.imread('SLICY.JPG')\n",
    "img5 = sk.color.rgb2gray(img5)\n",
    "img5 = resize(img5,(32,32),anti_aliasing=True)\n",
    "\n",
    "img6 = io.imread('T62.JPG')\n",
    "img6 = sk.color.rgb2gray(img6)\n",
    "img6 = resize(img6,(32,32),anti_aliasing=True)\n",
    "\n",
    "img7 = io.imread('ZIL.JPG')\n",
    "img7 = sk.color.rgb2gray(img7)\n",
    "img7 = resize(img7,(32,32),anti_aliasing=True)\n",
    "\n",
    "img8 = io.imread('ZSU.JPG')\n",
    "img8 = sk.color.rgb2gray(img8)\n",
    "img8 = resize(img8,(32,32),anti_aliasing=True)\n",
    "\n",
    "\n",
    "# Testing Dataset\n",
    "test_img1 = io.imread('2S1LG.JPG')\n",
    "test_img1 = sk.color.rgb2gray(test_img1)\n",
    "test_img1 = resize(test_img1,(32,32),anti_aliasing=True)\n",
    "\n",
    "test_img2 = io.imread('BRDM2ALG.JPG')\n",
    "test_img2 = sk.color.rgb2gray(test_img2)\n",
    "test_img2 = resize(test_img2,(32,32),anti_aliasing=True)\n",
    "\n",
    "test_img3 = io.imread('BRDM2LG.JPG')\n",
    "test_img3 = sk.color.rgb2gray(test_img3)\n",
    "test_img3 = resize(test_img3,(32,32),anti_aliasing=True)\n",
    "\n",
    "test_img4 = io.imread('BTR60LG.JPG')\n",
    "test_img4 = sk.color.rgb2gray(test_img4)\n",
    "test_img4 = resize(test_img4,(32,32),anti_aliasing=True)\n",
    "\n",
    "test_img5 = io.imread('D7LG.JPG')\n",
    "test_img5 = sk.color.rgb2gray(test_img5)\n",
    "test_img5 = resize(test_img5,(32,32),anti_aliasing=True)\n",
    "\n",
    "test_img6 = io.imread('SLICYLG.JPG')\n",
    "test_img6 = sk.color.rgb2gray(test_img6)\n",
    "test_img6 = resize(test_img6,(32,32),anti_aliasing=True)\n",
    "\n",
    "test_img7 = io.imread('T62LG.JPG')\n",
    "test_img7 = sk.color.rgb2gray(test_img7)\n",
    "test_img7 = resize(test_img7,(32,32),anti_aliasing=True)\n",
    "\n",
    "test_img8 = io.imread('ZIL131LG.JPG')\n",
    "test_img8 = sk.color.rgb2gray(test_img8)\n",
    "test_img8 = resize(test_img8,(32,32),anti_aliasing=True)\n",
    "\n",
    "test_img9 = io.imread('ZSU23ALG.JPG')\n",
    "test_img9 = sk.color.rgb2gray(test_img9)\n",
    "test_img9 = resize(test_img9,(32,32),anti_aliasing=True)\n",
    "\n",
    "test_img10 = io.imread('ZSU23LG.JPG')\n",
    "test_img10 = sk.color.rgb2gray(test_img10)\n",
    "test_img10 = resize(test_img10,(32,32),anti_aliasing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training signals\n",
    "signal1 = np.array(img1.flatten(), dtype=np.float64)\n",
    "signal1 = (signal1[np.newaxis])\n",
    "\n",
    "signal2 = np.array(img2.flatten(), dtype=np.float64)\n",
    "signal2 = (signal2[np.newaxis])\n",
    "\n",
    "signal3 = np.array(img3.flatten(), dtype=np.float64)\n",
    "signal3 = (signal3[np.newaxis])\n",
    "\n",
    "signal4 = np.array(img4.flatten(), dtype=np.float64)\n",
    "signal4 = (signal4[np.newaxis])\n",
    "\n",
    "signal5 = np.array(img5.flatten(), dtype=np.float64)\n",
    "signal5 = (signal5[np.newaxis])\n",
    "\n",
    "signal6 = np.array(img6.flatten(), dtype=np.float64)\n",
    "signal6 = (signal6[np.newaxis])\n",
    "\n",
    "signal7 = np.array(img7.flatten(), dtype=np.float64)\n",
    "signal7 = (signal7[np.newaxis])\n",
    "\n",
    "signal8 = np.array(img8.flatten(), dtype=np.float64)\n",
    "signal8 = (signal8[np.newaxis])\n",
    "\n",
    "# Testing signals\n",
    "signal9 = np.array(test_img1.flatten(), dtype=np.float64)\n",
    "signal9 = (signal9[np.newaxis])\n",
    "\n",
    "signal10 = np.array(test_img2.flatten(), dtype=np.float64)\n",
    "signal10 = (signal10[np.newaxis])\n",
    "\n",
    "signal11 = np.array(test_img3.flatten(), dtype=np.float64)\n",
    "signal11 = (signal11[np.newaxis])\n",
    "\n",
    "signal12 = np.array(test_img4.flatten(), dtype=np.float64)\n",
    "signal12 = (signal12[np.newaxis])\n",
    "\n",
    "signal13 = np.array(test_img5.flatten(), dtype=np.float64)\n",
    "signal13 = (signal13[np.newaxis])\n",
    "\n",
    "signal14 = np.array(test_img6.flatten(), dtype=np.float64)\n",
    "signal14 = (signal14[np.newaxis])\n",
    "\n",
    "signal15 = np.array(test_img7.flatten(), dtype=np.float64)\n",
    "signal15 = (signal15[np.newaxis])\n",
    "\n",
    "signal16 = np.array(test_img8.flatten(), dtype=np.float64)\n",
    "signal16 = (signal16[np.newaxis])\n",
    "\n",
    "signal17 = np.array(test_img9.flatten(), dtype=np.float64)\n",
    "signal17 = (signal17[np.newaxis])\n",
    "\n",
    "signal18 = np.array(test_img10.flatten(), dtype=np.float64)\n",
    "signal18 = (signal18[np.newaxis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining signals\n",
    "signals = np.vstack([signal1,signal2,signal3,signal4,signal5,signal6,signal7,signal8])\n",
    "\n",
    "testSignals = np.vstack([signal9,signal10,signal11,signal12,signal13,signal14,signal15,signal16,signal17,signal18])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main code for our research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the parameters that provided the biggest accuracy rate.\n",
    "sparsity=16\n",
    "num_coms=1040\n",
    "max_iter=100   \n",
    "\n",
    "# This step helps us update the dictionary\n",
    "def updateDict(D, A, B):\n",
    "    D = D.copy()\n",
    "    DA  = D.dot(A)\n",
    "    count = 0\n",
    "    for j in range(D.shape[1]):\n",
    "        u_j = (B[:, j] - np.matmul(D, A[:, j])) / A[j, j] + D[:, j]\n",
    "        D[:, j] = u_j/max([1, np.linalg.norm(u_j)])\n",
    "    return D\n",
    "\n",
    "# Draws a random signal from the data\n",
    "def randomSignal(signals):\n",
    "    rand = random.randint(0,signals.shape[0]-1)\n",
    "    return signals[rand]\n",
    "\n",
    "# Dynamic stopping criteria\n",
    "def OrthogonalMatchingPursuits(D, x, L):\n",
    "    residual = x\n",
    "    idx = []\n",
    "    \n",
    "    stopping_condition = lambda: len(idx) == L\n",
    "    \n",
    "    while not stopping_condition():\n",
    "        lam = np.abs(np.dot(residual, D)).argmax()\n",
    "        idx.append(lam)\n",
    "        gamma, _, _, _ = np.linalg.lstsq(D[:, idx], x, rcond=None)\n",
    "        residual = x - np.dot(D[:, idx], gamma)\n",
    "    alpha = np.zeros(D.shape[1])\n",
    "    for i,val in enumerate(idx):\n",
    "        alpha[val]=gamma[i]\n",
    "    return alpha\n",
    "\n",
    "# Trains dictionary\n",
    "def trainDictionary(signals,sparsity,num_coms,max_iter):\n",
    "#     Initialises dictionary to random signals from data\n",
    "    atoms = np.zeros((signals.shape[1], num_coms))\n",
    "    for i in range(num_coms):\n",
    "        atoms[:,i] = randomSignal(signals)\n",
    "\n",
    "    signal = randomSignal(signals)\n",
    "    A = np.zeros((num_coms, num_coms))\n",
    "    B = np.zeros((signals.shape[1], num_coms))\n",
    "    for t in range(1,max_iter):\n",
    "        signal = randomSignal(signals)\n",
    "        alpha = OrthogonalMatchingPursuits(atoms,signal,num_coms-sparsity)\n",
    "        A += (alpha.dot(alpha.T))\n",
    "        B += (signal[:, None]*alpha[None,:])\n",
    "        atoms = updateDict(atoms, A, B)\n",
    "\n",
    "    return atoms\n",
    "\n",
    "# SETS and returns coeficients\n",
    "def Coeffs(atoms,signals,num_coms,sparsity):\n",
    "    coefs = np.zeros((signals.shape[0],num_coms))\n",
    "    \n",
    "    for i in range(signals.shape[0]):\n",
    "        coefs[i] = OrthogonalMatchingPursuits(atoms, signals[i],L=num_coms-sparsity)\n",
    "\n",
    "    return coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning the Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnedDictionary = trainDictionary(signals,sparsity,num_coms,max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning the Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = Coeffs(learnedDictionary,signals,num_coms,sparsity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The classification step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ASRC(X,y,coeffs,alpha):\n",
    "    \n",
    "#     Normalising the learned dictionary\n",
    "    X_normalized = []\n",
    "    for i in range(X.shape[1]):\n",
    "        norm = np.sqrt(np.sum((X[:,i])**2))\n",
    "        X[:,i] = X[:,i]/norm\n",
    "    \n",
    "    X_normalized = X\n",
    "\n",
    "    residuals = []\n",
    "    for i in range(coeffs.shape[0]):\n",
    "#         Coding y over X\n",
    "        x1 = np.dot(X_normalized,coeffs[i,:])[:,np.newaxis]        \n",
    "        x1 = np.subtract(y.T,x1)\n",
    "        norm = np.sqrt(np.sum((x1)**2))\n",
    "        x1 = x1/norm\n",
    "        \n",
    "#       Calculating the trace norm\n",
    "        x2 = np.dot(X_normalized,np.diag(coeffs[i,:]))\n",
    "        x2 = 1e-18*x2.sum()\n",
    "        \n",
    "        for i in range(len(x1)):\n",
    "            x1[i] = x1[i] + x2*1e-8\n",
    "\n",
    "#         Calculating the residual\n",
    "        residuals.append(np.sqrt(np.sum((x1)**2)))\n",
    "        \n",
    "    return residuals.index(min(residuals))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 20.0%\n"
     ]
    }
   ],
   "source": [
    "trainResult = [0,1,2,3,4,5,6,7]\n",
    "testResult = [0,1,1,2,3,4,5,6,7,7]\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in range(len(trainResult)):\n",
    "    temp = ASRC(learnedDictionary,signals[i],coeffs,2.1)\n",
    "#     print(temp,trainResult[i])\n",
    "    if temp==trainResult[i]:\n",
    "        count = count + 1\n",
    "\n",
    "# Uncomment the line below to see the accuracy of the model on the signals used to train the dictionary        \n",
    "# print('The accuracy of the model using the training data is '+str(count/8))\n",
    "count = 0\n",
    "\n",
    "for i in range(len(testResult)):\n",
    "    temp = ASRC(learnedDictionary,testSignals[i],coeffs,2.1)\n",
    "#     print(temp,testResult[i])\n",
    "    if temp==testResult[i]:\n",
    "        count = count + 1\n",
    "\n",
    "print('The accuracy of the model is '+str((count/10)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing our model with other well performing classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Naive Bayes Classifier is 33.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf = BernoulliNB()\n",
    "clf.fit(signals,trainResult)\n",
    "\n",
    "prediction = clf.predict(testSignals)\n",
    "\n",
    "confusionMatrix = confusion_matrix(testResult, prediction)\n",
    "accuracy  = (confusionMatrix[0][0]+confusionMatrix[1][1])/(confusionMatrix[0][0]+confusionMatrix[1][1]+confusionMatrix[1][0]+confusionMatrix[0][1])\n",
    "\n",
    "print('The accuracy of the Naive Bayes Classifier is '+str(accuracy*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Decision Tree classifier is 100.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(signals,trainResult)\n",
    "\n",
    "prediction = clf.predict(testSignals)\n",
    "\n",
    "confusionMatrix = confusion_matrix(testResult, prediction)\n",
    "accuracy  = (confusionMatrix[0][0]+confusionMatrix[1][1])/(confusionMatrix[0][0]+confusionMatrix[1][1]+confusionMatrix[1][0]+confusionMatrix[0][1])\n",
    "\n",
    "print('The accuracy of the Decision Tree classifier is '+str(accuracy*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Single Vector Machine(SVM) classifier is 100.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "clf = make_pipeline(StandardScaler(),LinearSVC(random_state=0, tol=1e-5))\n",
    "clf.fit(signals,trainResult)\n",
    "\n",
    "prediction = clf.predict(testSignals)\n",
    "\n",
    "confusionMatrix = confusion_matrix(testResult, prediction)\n",
    "accuracy  = (confusionMatrix[0][0]+confusionMatrix[1][1])/(confusionMatrix[0][0]+confusionMatrix[1][1]+confusionMatrix[1][0]+confusionMatrix[0][1])\n",
    "\n",
    "print('The accuracy of the Single Vector Machine(SVM) classifier is '+str(accuracy*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Nearest Neighbour(NN) Classifier is 66.66666666666666%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=2)\n",
    "clf.fit(signals,trainResult)\n",
    "\n",
    "prediction = clf.predict(testSignals)\n",
    "\n",
    "confusionMatrix = confusion_matrix(testResult, prediction)\n",
    "accuracy  = (confusionMatrix[0][0]+confusionMatrix[1][1])/(confusionMatrix[0][0]+confusionMatrix[1][1]+confusionMatrix[1][0]+confusionMatrix[0][1])\n",
    "\n",
    "print('The accuracy of the Nearest Neighbour(NN) Classifier is '+str(accuracy*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
